{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabula-py\n",
      "  Downloading tabula_py-2.9.0-py3-none-any.whl (12.0 MB)\n",
      "     ---------------------------------------- 12.0/12.0 MB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\sdwee\\anaconda3\\lib\\site-packages (from tabula-py) (1.26.4)\n",
      "Collecting distro\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: pandas>=0.25.3 in c:\\users\\sdwee\\anaconda3\\lib\\site-packages (from tabula-py) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sdwee\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=0.25.3->tabula-py) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sdwee\\anaconda3\\lib\\site-packages (from pandas>=0.25.3->tabula-py) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sdwee\\anaconda3\\lib\\site-packages (from pandas>=0.25.3->tabula-py) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sdwee\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.16.0)\n",
      "Installing collected packages: distro, tabula-py\n",
      "Successfully installed distro-1.9.0 tabula-py-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tabula-py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Educational\\Sri Lanka Data\\childprotection.gov.lk\\child_protection_data\n",
      "['Statistical-data_-_Year_2022.pdf', 'Statistical-data_-_Year_2023.pdf', 'Statistical_data_-_Year_2010.pdf', 'Statistical_data_-_Year_2011.pdf', 'Statistical_data_-_Year_2012.pdf', 'Statistical_data_-_Year_2013.pdf', 'Statistical_data_-_Year_2014.pdf', 'Statistical_data_-_Year_2015.pdf', 'Statistical_data_-_Year_2016.pdf', 'Statistical_data_-_Year_2017.pdf', 'Statistical_data_-_Year_2018.pdf', 'Statistical_data_-_Year_2019.pdf', 'Statistical_data_-_Year_2020.pdf', 'Statistical_data_-_Year_2021.pdf']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "# List all files in the data directory\n",
    "data_directory = './data/'  # Adjust this path if necessary\n",
    "files_in_data_directory = os.listdir(data_directory)\n",
    "print(files_in_data_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet demonstrates how to use the tabula library in Python to read tables from a PDF file and store them in a variable named tables. The tabula library is a popular tool for extracting table data from PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error importing jpype dependencies. Fallback to subprocess.\n",
      "No module named 'jpype'\n",
      "c:\\Users\\sdwee\\anaconda3\\lib\\site-packages\\tabula\\io.py:1045: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "\n",
    "# Read PDF file\n",
    "file_path = 'data/PDF/Statistical_data_-_Year_2017.pdf'\n",
    "tables = tabula.read_pdf(file_path, pages='all', multiple_tables=True)\n",
    "\n",
    "# tables is a list of DataFrame objects, where each DataFrame corresponds to a table found in the PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      Unnamed: 0 District  No of complaints\n",
       " 0         Ampara      NaN               208\n",
       " 1    Anuradapura      NaN               441\n",
       " 2        Badulla      NaN               198\n",
       " 3      Baticoloa      NaN               179\n",
       " 4        Colombo      NaN              1302\n",
       " 5          Galle      NaN               586\n",
       " 6        Gampaha      NaN               974\n",
       " 7    Hambanthota      NaN               310\n",
       " 8         Jaffna      NaN               188\n",
       " 9      Kaluthara      NaN               591\n",
       " 10         Kandy      NaN               382\n",
       " 11       Kegalle      NaN               286\n",
       " 12   Kilinochchi      NaN               126\n",
       " 13    Kurunegala      NaN               681\n",
       " 14        Mannar      NaN                69\n",
       " 15        Matale      NaN               200\n",
       " 16        Matara      NaN               316\n",
       " 17    Monaragala      NaN               226\n",
       " 18     Mulathivu      NaN               132\n",
       " 19  Nuwara Eliya      NaN               184\n",
       " 20   Polonnaruwa      NaN               245\n",
       " 21       Puttlum      NaN               403\n",
       " 22    Rathnapura      NaN               518\n",
       " 23    Trincomali      NaN               138\n",
       " 24      Vavuniya      NaN               131\n",
       " 25           NaN    Total              9014,\n",
       "                                Type of abuse  No of complaints\n",
       " 0          14. ACO -  Restriction on payment                 1\n",
       " 1                  286A. Obscene publication                 8\n",
       " 2                      288. Procuring to beg               312\n",
       " 3      288B. Trafficking Restricted Articles                28\n",
       " 4                  308A. Cruelty to Children              2144\n",
       " 5                     345. Sexual Harassment               501\n",
       " 6   352. Kidnapping from lawful guardianship               145\n",
       " 7                             353. Abduction                42\n",
       " 8                          360C. Trafficking               116\n",
       " 9                   360E. Soliciting a child                10\n",
       " 10                                 363. Rape               340\n",
       " 11                              364A. Incest                 1\n",
       " 12                    365. Unnatural Offence                 1\n",
       " 13                     365A. Gross Indecency                 5\n",
       " 14                  365B. Grave sexual abuse               309\n",
       " 15           71. CYPO -  Neglect of Children               390\n",
       " 16               76. CYPO -  Sale of tobacco                 3\n",
       " 17                               Child Labor               269\n",
       " 18                      Compulsory Education              1324\n",
       " 19                         Domestic Violence                80\n",
       " 20                      Juvenile Delinquency               492\n",
       " 21                                     MISC.              2493\n",
       " 22                                     Total              9014]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sdwee\\anaconda3\\lib\\site-packages\\tabula\\io.py:1045: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "\n",
    "# Assuming the previous code for reading PDF tables\n",
    "file_path = 'data/PDF-text/Statistical_data_-_Year_2017.pdf'\n",
    "tables = tabula.read_pdf(file_path, pages='all', multiple_tables=True)\n",
    "\n",
    "# Iterate over each table (DataFrame) in the list\n",
    "for index, table in enumerate(tables):\n",
    "    # Define a CSV file path for each table\n",
    "    csv_file_path = f'data/CSV/table_{index}_from_2017.pdf.csv'\n",
    "    # Convert the DataFrame to a CSV file\n",
    "    table.to_csv(csv_file_path, index=False)  # index=False to avoid writing row indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_csv(year):\n",
    "    \n",
    "    file_path = f'data/PDF-text/Statistical_data_-_Year_{year}.pdf'\n",
    "    tables = tabula.read_pdf(file_path, pages='all', multiple_tables=True)\n",
    "\n",
    "    for index, table in enumerate(tables):\n",
    "        csv_file_path = f'data/CSV/table_{index}_from_{year}.csv'\n",
    "        excel_file_path = f'data/CSV/table_{index}_from_{year}.xlsx'\n",
    "\n",
    "        try:\n",
    "            table.to_csv(csv_file_path, index=False, encoding='utf-8', errors='replace')\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Error writing table {index} to CSV: {e}. Attempting to write to Excel instead.\")\n",
    "            try:\n",
    "                table.to_excel(excel_file_path, index=False)\n",
    "            except Exception as excel_error:\n",
    "                print(f\"Failed to write table {index} to Excel: {excel_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 csv are created.\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x96 in position 35110: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m2024\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mpdf_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m csv are created.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll files are done\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m, in \u001b[0;36mpdf_to_csv\u001b[1;34m(year)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpdf_to_csv\u001b[39m(year):\n\u001b[0;32m      3\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/PDF-text/Statistical_data_-_Year_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[43mtabula\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiple_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, table \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tables):\n\u001b[0;32m      7\u001b[0m         csv_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/CSV/table_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_from_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myear\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\sdwee\\anaconda3\\lib\\site-packages\\tabula\\io.py:395\u001b[0m, in \u001b[0;36mread_pdf\u001b[1;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, user_agent, use_raw_url, pages, guess, area, relative_area, lattice, stream, password, silent, columns, relative_columns, format, batch, output_path, force_subprocess, options)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is empty. Check the file, or download it manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 395\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtabula_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjava_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_subprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_subprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m temporary:\n",
      "File \u001b[1;32mc:\\Users\\sdwee\\anaconda3\\lib\\site-packages\\tabula\\io.py:82\u001b[0m, in \u001b[0;36m_run\u001b[1;34m(options, java_options, path, encoding, force_subprocess)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(java_options) \u001b[38;5;241m-\u001b[39m IGNORED_JAVA_OPTIONS:\n\u001b[0;32m     80\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava_options is ignored until rebooting the Python process.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tabula_vm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_tabula_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sdwee\\anaconda3\\lib\\site-packages\\tabula\\backend.py:117\u001b[0m, in \u001b[0;36mSubprocessTabula.call_tabula_java\u001b[1;34m(self, options, path)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstderr:\n\u001b[0;32m    116\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot stderr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JavaNotFoundError(JAVA_NOT_FOUND_ERROR)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x96 in position 35110: invalid start byte"
     ]
    }
   ],
   "source": [
    "for year in range(2022, 2024):\n",
    "    pdf_to_csv(year)\n",
    "\n",
    "    print(f'{year} csv are created.')\n",
    "\n",
    "print('All files are done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am having same error continusly. Following code handel the exception properly but the code is not create csv for 2022 and 2023 pdfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022 processing completed.\n",
      "Error reading PDF for year 2023: 'utf-8' codec can't decode byte 0x96 in position 35110: invalid start byte. Skipping this file.\n",
      "2023 processing completed.\n",
      "All files processing done.\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "\n",
    "def pdf_to_csv(year):\n",
    "    file_path = f'data/PDF-text/Statistical_data_-_Year_{year}.pdf'\n",
    "    \n",
    "    try:\n",
    "        tables = tabula.read_pdf(file_path, pages='all', multiple_tables=True)\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error reading PDF for year {year}: {e}. Skipping this file.\")\n",
    "        return  # Skip processing this file due to read error\n",
    "    \n",
    "    for index, table in enumerate(tables):\n",
    "        csv_file_path = f'data/CSV/table_{index}_from_{year}.csv'\n",
    "        excel_file_path = f'data/CSV/table_{index}_from_{year}.xlsx'\n",
    "\n",
    "        try:\n",
    "            table.to_csv(csv_file_path, index=False, encoding='utf-8', errors='replace')\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Error writing table {index} to CSV: {e}. Attempting to write to Excel instead.\")\n",
    "            try:\n",
    "                table.to_excel(excel_file_path, index=False)\n",
    "            except Exception as excel_error:\n",
    "                print(f\"Failed to write table {index} to Excel: {excel_error}\")\n",
    "\n",
    "for year in range(2022, 2024):\n",
    "    pdf_to_csv(year)\n",
    "    print(f'{year} processing completed.')\n",
    "\n",
    "print('All files processing done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Approch Using PDFPlumber (Python Library):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.10.4-py3-none-any.whl (54 kB)\n",
      "     -------------------------------------- 54.7/54.7 kB 408.1 kB/s eta 0:00:00\n",
      "Collecting pdfminer.six==20221105\n",
      "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 5.5 MB/s eta 0:00:00\n",
      "Collecting pypdfium2>=4.18.0\n",
      "  Downloading pypdfium2-4.27.0-py3-none-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\sdwee\\anaconda3\\lib\\site-packages (from pdfplumber) (10.0.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\sdwee\\anaconda3\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\sdwee\\anaconda3\\lib\\site-packages (from pdfminer.six==20221105->pdfplumber) (41.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\sdwee\\anaconda3\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sdwee\\anaconda3\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
      "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
      "Successfully installed pdfminer.six-20221105 pdfplumber-0.10.4 pypdfium2-4.27.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No table found on page 1 of year 2022.\n",
      "No table found on page 2 of year 2022.\n",
      "2022 processing completed with PDFPlumber.\n",
      "Table 0 from year 2023 saved to CSV.\n",
      "Table 1 from year 2023 saved to CSV.\n",
      "Table 2 from year 2023 saved to CSV.\n",
      "Table 3 from year 2023 saved to CSV.\n",
      "2023 processing completed with PDFPlumber.\n",
      "All files processing done with PDFPlumber.\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def pdf_to_csv_with_pdfplumber(year):\n",
    "    file_path = f'data/PDF-text/Statistical_data_-_Year_{year}.pdf'\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            # Attempt to extract tables from the page\n",
    "            table = page.extract_table()\n",
    "            if table:  # If a table is found\n",
    "                df = pd.DataFrame(table[1:], columns=table[0])\n",
    "                csv_file_path = f'data/CSV/table_{i}_from_{year}.csv'\n",
    "                df.to_csv(csv_file_path, index=False)\n",
    "                print(f\"Table {i} from year {year} saved to CSV.\")\n",
    "            else:\n",
    "                print(f\"No table found on page {i+1} of year {year}.\")\n",
    "\n",
    "for year in range(2010, 2021):\n",
    "    pdf_to_csv_with_pdfplumber(year)\n",
    "    print(f'{year} processing completed with PDFPlumber.')\n",
    "\n",
    "print('All files processing done with PDFPlumber.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert 2023 pdf to csv but still 2022 is not successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
